---
title: "分類（性能指標）"
output: html_document
---

```{r}
library(tidyverse)
library(caret)
```

次のような分類結果について考える。（補足：出力変数は数値ではなくfactorである。）

```{r}
# 正解
my_answer <- factor(c(0, 0, 0, 0, 1, 1, 0, 1, 1, 1))

# 陽性確率
my_prob <- c(0.1, 0.2 ,0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0) # 1:10 / 10 # が簡単
```

（仮に）確率が0.5以上のものを陽性とする。

```{r}
(my_prediction <- factor(ifelse(my_prob >= 0.5, 1, 0)))
```

キーワード：

- 混同行列（confusion matrix）
- 陽性（positive），真陽性（true positive），偽陽性（false positive）
- 陰性（negative），真陰性（true negative），偽陰性（false negative）

`confusionMatrix()`を使って，さまざまな性能指標をまとめて求める。

```{r}
confusionMatrix(data = my_prediction, reference = my_answer, positive = "1", mode = "everything")
```

```{r}
(4 + 5) / 10    # accuracy（正答率・正解率）
5 / (0 + 5)     # sensitivity（感度），true positive rate（真陽性率），recall（再現率）と同じ
4 / (4 + 1)     # specificity（特異度），true negative rate（真陰性率）
5 / (1 + 5)     # positive predictive value（陽性反応適中度，PPV），precision（精度・適合率・信頼度）と同じ
4 / (4 + 0)     # negative predictive value（陰性反応適中度）
p <- 5 / (1 + 5)     # precision（精度・適合率・信頼度），positive predictive value（陽性反応適中度，PPV）と同じ
r <- 5 / (0 + 5)     # recall（再現率），sensitivity（感度）と同じ
1 / ((1/p + 1/r)/2) # F1（精度pと再現率rの調和平均）
(0 + 5) / 10    # prevalence（有病率）
5 / 10          # detection rate（検出率）
(1 + 5) / 10    # detection prevalence
(1.0 + 0.8) / 2 # balanced accuracy（感度と特異度の平均）
```

感度と特異度の組み合わせや，精度と再現率の組み合わせを使うことが多い。

Kappaはk統計量（kappa statistic）と呼ばれる指標で，予想が偶然当たる確率eを考慮した正解率である。eは，
陽性と予測する確率×疾患ありの確率 + 陰性と予測する確率×疾患なしの確率である，この例では次のように計算できる。

```{r}
e <- 0.6*0.5+0.4*0.5
```

正解率をpとすると，k統計量は(p-e)/(1-e)で定義される。

```{r}
p <- 0.9
(p - e) / (1 - e)
```

正解率とk統計量は，二値分類でない場合にも使える。

**練習：** 陽性と見なす確率を1から0まで0.1刻みで変化させ，false positive rate（感度）とtrue positive rate（1-特異度）がどのように変わるか調べよ。

```{r}
tmp <- data.frame(
  fpr = c(0, 0, 0, 0.2, 0.2, 0.2, 0.4, 0.6, 0.8, 1, 1),
  tpr = c(0.2, 0.4, 0.6, 0.6, 0.8, 1, 1, 1, 1, 1, 1))
ggplot(data = tmp, mapping = aes(x = fpr, y = tpr)) +
  geom_line()
```
```{r}
# 次のコードを使ってもよい。
f <- function(p) {
  my_answer <- factor(c(0, 0, 0, 0, 1, 1, 0, 1, 1, 1))
  my_prediction <- factor(c(rep(1, p), rep(0, 10 - p)))
  my_report <- confusionMatrix(data = my_prediction, reference = my_answer, positive = "1", mode = "everything")
  tpr <- my_report$byClass['Sensitivity'][[1]]
  fpr <- 1 - my_report$byClass['Specificity'][[1]]
  data.frame(tpr = tpr, fpr = fpr)
}
f(3)
```

### ROC曲線

```{r, eval=FALSE}
install.packages('ROCR')
```

```{r}
# このコードは理解できなくてよい。
library(ROCR)

my_pred <- prediction(predictions = my_prob, labels = my_answer)
my_perf <- performance(prediction.obj = my_pred, measure = "tpr", x.measure = "fpr")
plot(my_perf)
```

ROC曲線の下の部分の面積をAUC（area under the curve）と呼ぶ。この値が1に近いほど分類器の性能がよいことが期待される。（ランダムな分類器のAUCは0.5）

```{r}
performance(prediction.obj = my_pred, measure = "auc")@y.values[[1]]
```

### 練習

タイタニック（その1）の学習におけるROC曲線を描いてみよう。

```{r,cache=TRUE}
my_data <- epitools::expand.table(Titanic)
my_index <- sample(1:nrow(my_data), 0.8 * nrow(my_data))
my_train <- my_data[my_index, ]
my_test <- my_data[-my_index, ]
my_result <- train(form = Survived ~ ., data = my_train, method = "knn")
my_train_prediction <- predict(object = my_result, newdata = my_train)
confusionMatrix(data = my_train_prediction, reference = my_train$Survived, positive = "Yes", mode = "everything")
```

ROC曲線を描くためには，陽性となる確率が必要。

```{r}
my_prob <- predict(object = my_result, newdata = my_train, type = "prob")$Yes
head(my_prob)
```

```{r}
# このコードは理解できなくてよい。
my_pred <-prediction(predictions = my_prob, labels = my_train$Survived)
my_perf <- performance(prediction.obj = my_pred, measure = "tpr", x.measure = "fpr")
plot(my_perf)
```

AUCを求める。

```{r}
performance(prediction.obj = my_pred, measure = "auc")@y.values[[1]]
```